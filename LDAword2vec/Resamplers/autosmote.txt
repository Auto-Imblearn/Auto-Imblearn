The proposed model, AutoSMOTE, is an automated over-sampling algorithm designed to optimize the classification performance on imbalanced datasets using deep hierarchical reinforcement learning.

AutoSMOTE addresses the challenge of imbalanced learning, where there is a disproportionate ratio of training samples in each class. Traditional over-sampling techniques like SMOTE generate synthetic samples for the minority class but rely heavily on heuristics and can introduce noisy samples. AutoSMOTE leverages a learning-based approach to optimize the over-sampling strategy and improve classification performance.

AutoSMOTE employs a hierarchical decision process with high-level and low-level decisions. At the high level, the model determines the number of synthetic samples to generate for each minority instance. At the low level, it decides which neighbors to interpolate and the interpolation weights to generate synthetic samples.

The over-sampling process is formulated as a Markov Decision Process (MDP), with states representing the data distribution, actions corresponding to generating synthetic samples, and rewards based on the classification performance on validation data. The state features describe the current data distribution and the instance being processed. High-level actions determine the number of synthetic samples to generate, while low-level actions select neighbors and interpolation weights. The reward is calculated based on the performance metric on the validation set, guiding the reinforcement learning agent.

Deep hierarchical reinforcement learning is used to optimize the high-level and low-level policies collaboratively. This hierarchical RL framework allows AutoSMOTE to make decisions at different levels, reducing the search space and improving efficiency.

The workflow of AutoSMOTE starts with initializing the RL agent with an initial state representing the current data distribution. The high-level policy then decides the number of synthetic samples for each minority instance. For each instance, the low-level policy selects neighbors and interpolation weights to generate synthetic samples. The synthetic samples are generated and added to the training set. The classifier is trained on the augmented dataset, and its performance on the validation set is evaluated to calculate the reward. The RL agent updates its policies based on the received rewards, improving its over-sampling strategy iteratively.

AutoSMOTE has several advantages. It directly optimizes the classification performance metric on the validation set. Its hierarchical decision-making process efficiently reduces the search space and allows for personalized sampling strategies. Additionally, the framework can be extended to incorporate other sampling techniques and can be applied to various types of data.

Extensive experiments on six real-world datasets demonstrate that AutoSMOTE significantly outperforms state-of-the-art resampling algorithms and various SMOTE variants. The proposed model shows consistent performance across different classifiers and imbalanced ratios.

In summary, AutoSMOTE provides a robust and flexible solution to the imbalanced learning problem by leveraging deep hierarchical reinforcement learning to optimize synthetic sample generation and improve classification performance.

The EEGEyeState dataset includes 14,980 instances with 14 numerical features representing EEG signal attributes. These features are labeled as AF3, F7, F3, FC5, T7, P, O1, O2, P8, T8, FC6, F4, F8, and AF4. The dataset records whether the eye was open (0) or closed (1) during the EEG measurement. The data was collected using the Emotiv EEG Neuroheadset over a 117-second continuous measurement. This dataset is widely used in biomedical signal processing and neuroinformatics to develop and test machine learning models for EEG signal classification

The Electricity dataset involves electricity consumption data, focusing on predicting whether electricity demand will increase or decrease. It contains 45,312 instances with 14 numerical features, including time, date, and various electricity usage metrics. The class distribution is imbalanced, reflecting the real-world fluctuations in electricity consumption. This dataset is suitable for testing imbalanced learning techniques in time series forecasting and energy consumption prediction. It helps in developing models that can predict demand patterns and optimize energy distribution networks

This dataset relates to the detection of gamma rays using the Magic Gamma Telescope. It consists of 19,020 instances with ten features describing various properties of the detected signals. The class distribution is imbalanced, with a higher number of non-gamma-ray instances compared to gamma-ray instances. The features include signal characteristics such as the width, length, size, and energy of the detected particles. This dataset is commonly used in astrophysics and particle physics for testing classification algorithms and improving gamma-ray detection techniques

The Mozilla4 dataset involves product defect data from Mozilla, used to identify defect types in software products. It includes 15,000 instances and five features that capture different aspects of the product defects. The dataset is designed to simulate real-world imbalanced data scenarios in software defect prediction. The exact class distribution is imbalanced, with a higher prevalence of certain types of defects compared to others, providing a robust test case for imbalanced learning methods

This dataset contains instances of legitimate and phishing websites, represented by 111 features that describe various attributes of the URLs and HTML content. The full variant of the dataset includes 88,647 instances, with 58,000 labeled as legitimate websites and 30,647 labeled as phishing websites. A smaller variant consists of 58,645 instances. The features include information about the website's URL, HTML elements, and other heuristics used to detect phishing attempts. The data was collected from sources such as Google search, PhishTank, and OpenPhish between late 2020 and 2021. This dataset is crucial for developing machine learning models aimed at enhancing cybersecurity by detecting phishing websites

The Phoneme dataset is designed for phoneme recognition, distinguishing between nasal and oral sounds. It consists of 5,404 instances and six attributes. The class distribution is imbalanced, with approximately 70% of the instances representing nasal sounds (3,818 instances) and 30% representing oral sounds (1,586 instances). The dataset includes five numerical input variables that capture various audio characteristics, and a target variable indicating the phoneme class. This dataset is valuable for testing imbalanced learning methods in the context of audio signal processing. The data was collected from segmented audio files, and each series was extracted from audio collected via Google Translate, recorded at 22,050 Hz
